# -*- coding: utf-8 -*-
"""internship-loan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gtoiw_3DNzlj7xrFjOkCzUosJMY7aJI3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv("/content/LoanApprovalPrediction.csv")

data.head(20)

obj = (data.dtypes == 'object')
print("Categorical variables:",len(list(obj[obj].index)))

# Dropping Loan_ID column
data.drop(['Loan_ID'],axis=1,inplace=True)

obj = (data.dtypes == 'object')
object_cols = list(obj[obj].index)
plt.figure(figsize=(18,36))
index = 1

for col in object_cols:
  y = data[col].value_counts()
  plt.subplot(11,4,index)
  plt.xticks(rotation=90)
  sns.barplot(x=list(y.index), y=y)
  index +=1

from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder

# label_encoder object knows how to understand word labels
label_encoder = preprocessing.LabelEncoder()

# Identify categorical columns
obj = (data.dtypes == 'object')

# Loop through each categorical column
for col in list(obj[obj].index):
    data[col] = label_encoder.fit_transform(data[col])

    # Print the mapping for the current column
    print(f"Mapping for column '{col}':")
    for i, class_label in enumerate(label_encoder.classes_):
        print(f"{class_label} -> {i}")
    print()

# To find the number of columns with
# datatype==object
obj = (data.dtypes == 'object')
print("Categorical variables:",len(list(obj[obj].index)))

data.describe

plt.figure(figsize=(12,6))

sns.heatmap(data.corr(),cmap='BrBG',fmt='.2f',
			linewidths=2,annot=True)
'''The below heatmap is showing the correlation between Loan Amount and ApplicantIncome.
It also shows that Credit_History has a high impact on Loan_Status.'''

sns.catplot(x="Gender", y="Married",
			hue="Loan_Status",
			kind="bar",
			data=data)

for col in data.columns:
  data[col] = data[col].fillna(data[col].mean())
print(data.isna().sum())

from sklearn.model_selection import train_test_split

X = data.drop(['Loan_Status'],axis=1)
Y = data['Loan_Status']
X.shape,Y.shape

X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
													test_size=0.4,
													random_state=1)
X_train.shape, X_test.shape, Y_train.shape, Y_test.shape

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

from sklearn import metrics

knn = KNeighborsClassifier(n_neighbors=3)
rfc = RandomForestClassifier(n_estimators = 7,
							criterion = 'entropy',
							random_state =7)
svc = SVC()
lc = LogisticRegression()

# making predictions on the training set
for clf in (rfc, knn, svc,lc):
	clf.fit(X_train, Y_train)
	Y_pred = clf.predict(X_train)
	print("Accuracy score of ",
		clf.__class__.__name__,
		"=",100*metrics.accuracy_score(Y_train,
										Y_pred))

#to measure f1 score,auc and precision
import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.metrics import f1_score, roc_auc_score, precision_score


# making predictions on the testing set
for clf in (rfc, knn, svc,lc):
	clf.fit(X_train, Y_train)
	Y_pred = clf.predict(X_test)
	print("Accuracy score of ",
		clf.__class__.__name__,"=",
		100*metrics.accuracy_score(Y_test,
									Y_pred))

  # Calculate and print F1 score, AUC, and precision
	f1 = f1_score(Y_test, Y_pred)
	print(f"F1 Score of {clf.__class__.__name__}: {f1}")

	try:
		auc = roc_auc_score(Y_test, Y_pred)
		print(f"AUC of {clf.__class__.__name__}: {auc}")
	except ValueError:
		print(f"AUC calculation failed for {clf.__class__.__name__}. Check if the target variable is binary.")

	precision = precision_score(Y_test, Y_pred)
	print(f"Precision of {clf.__class__.__name__}: {precision}")
	print("-"*50)

data.head()

import pandas as pd
from sklearn import preprocessing

new_user_data = pd.DataFrame({
    'Gender': [1],  # Example: 1 for Male, 0 for Female (replace with actual encoded values)
    'Married': [1],
    'Dependents': [2],
    'Education': [0],
    'Self_Employed': [0], #
    'ApplicantIncome': [5849],
    'CoapplicantIncome': [0.0],
    'LoanAmount': [130.0],
    'Loan_Amount_Term': [360.0],
    'Credit_History': [1.0],
    'Property_Area': [2]
})


rfc = RandomForestClassifier(n_estimators = 7, criterion = 'entropy', random_state = 7)
rfc.fit(X_train, Y_train) #Fit the model again if you didn't save it
prediction = rfc.predict(new_user_data)


# Print the prediction
print("Loan Status Prediction:", prediction)
if prediction[0] == 1:
    print("Loan Approved")
else:
    print("Loan Not Approved")

import pickle
with open('model.pkl','wb') as files:
  pickle.dump(rfc,files)

